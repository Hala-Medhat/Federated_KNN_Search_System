{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "{'message': {'node_id': 2, 'prediction': [7, 7, 6], 'distances': [0.3971969268473038, 0.1397830694330423, 0.32300462126035157], 'request_id': '156153bd-9568-4074-9e65-69c7ce211079'}, 'signature': 'f'}\n",
      "The message sent by node 2 is not correctly signed\n",
      "{'message': {'node_id': 1, 'prediction': [6, 6, 6], 'distances': [0.02518019982513464, 0.05141108189816079, 0.05162731029869594], 'request_id': '156153bd-9568-4074-9e65-69c7ce211079'}, 'signature': '0867fd3f888d2610a2c4f6818e01b3c525158ab79931e26ea5e4f8099d2e9096'}\n",
      "{'message': {'node_id': 2, 'prediction': [6, 6, 6], 'distances': [0.030774054370998005, 0.04430344274200948, 0.050306759120160915], 'request_id': '156153bd-9568-4074-9e65-69c7ce211079'}, 'signature': '917e7db954f9eae34632842ed839650b586d8cf962291b26e624a1f179f623e9'}\n",
      "{'message': {'node_id': 3, 'prediction': [6, 6, 6], 'distances': [0.0373170632272567, 0.039360543012593174, 0.0504187186398124], 'request_id': '156153bd-9568-4074-9e65-69c7ce211079'}, 'signature': '8300b6cf421e5e865124034a2f5fc60654efbd31d8a28349391c28f4cdf70380'}\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "import redis\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "import threading\n",
    "import time\n",
    "import hmac\n",
    "import hashlib\n",
    "import json\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import numpy as np\n",
    "import uuid\n",
    "from collections import deque\n",
    "from cryptography.fernet import Fernet\n",
    "from cryptography.hazmat.backends import default_backend\n",
    "from cryptography.hazmat.primitives import hashes\n",
    "from cryptography.hazmat.primitives.kdf.hkdf import HKDF\n",
    "import base64\n",
    "\n",
    "\n",
    "# Encryption key (this should be securely shared between aggregator and nodes)\n",
    "key = b'password'\n",
    "hkdf = HKDF(\n",
    "    algorithm=hashes.SHA256(),  \n",
    "    length=32,\n",
    "    salt=None,    \n",
    "    info=None,    # You may also be able to remove this line\n",
    "     backend=default_backend() )\n",
    "key = base64.urlsafe_b64encode(hkdf.derive(key))\n",
    "cipher_suite = Fernet(key)\n",
    "\n",
    "SECRET_KEY = b'my_secret_key'\n",
    "\n",
    "class KNNAggregator:\n",
    "    def __init__(self, node_count, message_integrity=False, message_tampering=False, rate_limit_bool=False,encypt = False):\n",
    "        self.redis_client = redis.StrictRedis(host='localhost', port=6379, db=0, password='secret_key')\n",
    "        self.subscribe_channel = 'knn_response_channel'\n",
    "        self.query_channel = 'knn_query_channel'  # New channel for receiving search queries\n",
    "        self.node_count = node_count\n",
    "        self.weights = {1: 1.0, 2: 1.0, 3:1.0}\n",
    "        self.requests = {}\n",
    "        self.active_request_ids = set()\n",
    "        self.message_integrity = message_integrity\n",
    "        self.message_tampering = message_tampering\n",
    "        self.encrypt = encypt\n",
    "        self.rate_limit = 10\n",
    "        self.rate_limit_bool = rate_limit_bool\n",
    "        self.request_times = deque()\n",
    "        self._listen_thread = threading.Thread(target=self.listen_for_responses)\n",
    "        self._listen_thread.start()\n",
    "        self._query_thread = threading.Thread(target=self.listen_for_queries)\n",
    "        self._query_thread.start()\n",
    "\n",
    "    def sign_message(self, message):\n",
    "        message_json = json.dumps(message)\n",
    "        signature = hmac.new(SECRET_KEY, message_json.encode(), hashlib.sha256).hexdigest()\n",
    "        return {'message': message, 'signature': signature}\n",
    "\n",
    "    def verify_message(self, signed_message):\n",
    "        message_json = json.dumps(signed_message['message'])\n",
    "        expected_signature = hmac.new(SECRET_KEY, message_json.encode(), hashlib.sha256).hexdigest()\n",
    "        return hmac.compare_digest(expected_signature, signed_message['signature'])\n",
    "    \n",
    "    def check_rate_limit(self):\n",
    "        current_time = time.time()\n",
    "        while self.request_times and current_time - self.request_times[0] > 1:\n",
    "            self.request_times.popleft()\n",
    "        if len(self.request_times) < self.rate_limit:\n",
    "            self.request_times.append(current_time)\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def listen_for_responses(self):\n",
    "        pubsub = self.redis_client.pubsub()\n",
    "        pubsub.subscribe(self.subscribe_channel)\n",
    "        for message in pubsub.listen():\n",
    "            if message['type'] == 'message':\n",
    "                \n",
    "                signed_response = pickle.loads(message['data'])\n",
    "                # print(signed_response)\n",
    "                if self.message_integrity:\n",
    "                    if self.verify_message(signed_response):\n",
    "                        response = signed_response['message']\n",
    "                    else:\n",
    "                        print(f'The message sent by node {signed_response['message']['node_id']} is not correctly signed')\n",
    "                        continue\n",
    "                else:\n",
    "                    response = signed_response['message']\n",
    "\n",
    "                request_id = response['request_id']\n",
    "                if request_id in self.active_request_ids:\n",
    "                    if request_id in self.requests:\n",
    "                        self.requests[request_id].append(response)\n",
    "                    else:\n",
    "                        self.requests[request_id] = [response]\n",
    "\n",
    "    def listen_for_queries(self):\n",
    "        \n",
    "        pubsub = self.redis_client.pubsub()\n",
    "        pubsub.subscribe(self.query_channel)\n",
    "        for message in pubsub.listen():\n",
    "            if message['type'] == 'message':\n",
    "                if (self.rate_limit_bool and self.check_rate_limit()) or not self.rate_limit_bool:\n",
    "                    query_data = pickle.loads(message['data'])\n",
    "                    sample = query_data['sample']\n",
    "                    distance = query_data['distance']\n",
    "                    voting_method = query_data['voting_method']\n",
    "                    request_id = query_data['request_id']\n",
    "                    self.send_request(sample, distance,request_id)\n",
    "                    self.handle_responses(request_id, voting_method)\n",
    "                else:\n",
    "                    print(\"dropped\" ,request_id)\n",
    "        \n",
    "                \n",
    "    def send_request(self, sample, distance,request_id):\n",
    "        request_data = {'sample': sample, 'request_id': request_id}\n",
    "        \n",
    "        request_data_pickled = pickle.dumps(request_data)\n",
    "        if(self.encrypt):\n",
    "            request_data_pickled = cipher_suite.encrypt(request_data_pickled)\n",
    "        self.requests[request_id] = []\n",
    "        self.active_request_ids.add(request_id)\n",
    "        for node_id in range(1, self.node_count + 1):\n",
    "            self.redis_client.publish(f'knn_{distance}_request_channel_{node_id}', request_data_pickled)\n",
    "    \n",
    "    \n",
    "    # \n",
    "    def handle_responses(self, request_id, voting_method):\n",
    "        \n",
    "        timeout = 60  # Timeout in seconds\n",
    "        start_time = time.time()\n",
    "        while True:\n",
    "            if time.time() - start_time > timeout:\n",
    "                print(\"Timeout reached, terminating script.\")\n",
    "                self.redis_client.publish('knn_query_response_channel', pickle.dumps({'request_id': request_id, 'result': []}))\n",
    "                break\n",
    "                \n",
    "            # print(len(self.requests.get(request_id, [])))\n",
    "            if len(self.requests.get(request_id, [])) >= self.node_count:\n",
    "                if voting_method == 'majority_voting':\n",
    "                    result = self.majority_voting(request_id)\n",
    "                elif voting_method == 'min_distance':\n",
    "                    result = self.min_distance(request_id)\n",
    "                elif voting_method == 'weighted_voting':\n",
    "                    result = self.weighted_voting(request_id)\n",
    "                elif voting_method == 'distance_based_aggregation':\n",
    "                    result = self.distance_based_aggregation(request_id)\n",
    "                else:\n",
    "                    result = None\n",
    "\n",
    "                self.redis_client.publish('knn_query_response_channel', pickle.dumps({'request_id': request_id, 'result': result}))\n",
    "                break\n",
    "            time.sleep(0.1)  # Sleep briefly to avoid busy-waiting\n",
    "\n",
    "    def create_feature_vectors(self, request_id):\n",
    "        feature_vectors = []\n",
    "        responses = self.requests[request_id]\n",
    "        for response in responses:\n",
    "            distances = response['distances']\n",
    "            predictions = response['prediction']\n",
    "            feature_vector = np.concatenate([distances, predictions])\n",
    "            feature_vectors.append(feature_vector)\n",
    "        return np.array(feature_vectors)\n",
    "\n",
    "    def detect_anomalies_isolation_forest(self, request_id, contamination=0.1):\n",
    "        if self.message_tampering:\n",
    "            time.sleep(1)\n",
    "            feature_vectors = self.create_feature_vectors(request_id)\n",
    "            model = IsolationForest(contamination=contamination)\n",
    "            model.fit(feature_vectors)\n",
    "            predictions = model.predict(feature_vectors)\n",
    "            anomaly_indices = np.where(predictions == -1)[0]\n",
    "            responses = np.array(self.requests[request_id])\n",
    "            mask = np.ones(len(responses), dtype=bool)\n",
    "            mask[anomaly_indices] = False\n",
    "            self.requests[request_id] = responses[mask].tolist()\n",
    "\n",
    "    def majority_voting(self, request_id):\n",
    "        self.detect_anomalies_isolation_forest(request_id)\n",
    "        responses = self.requests[request_id]\n",
    "        all_predictions = [prediction for response in responses for prediction in response['prediction']]\n",
    "        # Find the majority class\n",
    "        final_prediction = max(set(all_predictions), key=all_predictions.count)\n",
    "        del self.requests[request_id]\n",
    "        self.active_request_ids.discard(request_id)\n",
    "        return final_prediction\n",
    "\n",
    "    def min_distance(self, request_id):\n",
    "        self.detect_anomalies_isolation_forest(request_id)\n",
    "        responses = self.requests[request_id]\n",
    "        all_predictions = []\n",
    "        all_distances = []\n",
    "        for response in responses:\n",
    "            all_distances.append(response['distances'])\n",
    "            all_predictions.append(response['prediction'])\n",
    "        flattened_distances = [item for sublist in all_distances for item in sublist]\n",
    "        flattened_predictions = [item for sublist in all_predictions for item in sublist]\n",
    "        min_index = flattened_distances.index(min(flattened_distances))\n",
    "        final_prediction = flattened_predictions[min_index]\n",
    "        del self.requests[request_id]\n",
    "        self.active_request_ids.discard(request_id)\n",
    "        return final_prediction\n",
    "\n",
    "    def weighted_voting(self, request_id):\n",
    "        self.detect_anomalies_isolation_forest(request_id)\n",
    "        responses = self.requests[request_id]\n",
    "        weighted_votes = defaultdict(float)\n",
    "        for response in responses:\n",
    "            node_id = response['node_id']\n",
    "            predictions = response['prediction']\n",
    "            weight = self.weights[node_id]\n",
    "            for prediction in predictions:\n",
    "                weighted_votes[prediction] += weight\n",
    "        final_prediction = max(weighted_votes, key=weighted_votes.get)\n",
    "        del self.requests[request_id]\n",
    "        self.active_request_ids.discard(request_id)\n",
    "        return final_prediction\n",
    "\n",
    "    def distance_based_aggregation(self, request_id):\n",
    "        self.detect_anomalies_isolation_forest(request_id)\n",
    "        responses = self.requests[request_id]\n",
    "        distance_weighted_votes = defaultdict(float)\n",
    "        for response in responses:\n",
    "            node_id = response['node_id']\n",
    "            predictions = response['prediction']\n",
    "            distances = response['distances']\n",
    "            for i, prediction in enumerate(predictions):\n",
    "                weight = 1 / (distances[i] + 1e-5)\n",
    "                distance_weighted_votes[prediction] += weight\n",
    "        final_prediction = max(distance_weighted_votes, key=distance_weighted_votes.get)\n",
    "        del self.requests[request_id]\n",
    "        self.active_request_ids.discard(request_id)\n",
    "        return final_prediction\n",
    "\n",
    "\n",
    "# Initialize the aggregator\n",
    "\n",
    "aggregator = KNNAggregator(node_count=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregator.rate_limit_bool = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregator.rate_limit_bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defense aganist message tampering during transmission\n",
    "aggregator.message_integrity = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allow tampering during transmission\n",
    "aggregator.message_integrity = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregator.encrypt = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregator.encrypt = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defense aganist label flipping\n",
    "aggregator.message_tampering = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allow  label flipping\n",
    "aggregator.message_tampering = False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
